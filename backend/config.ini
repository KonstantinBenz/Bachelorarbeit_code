[FastAPI]
enable_tls = "true"
ip_address = "0.0.0.0"
port = "8000"

[cors]
allow_origins     = ["*"]
allow_credentials = "True"
allow_methods     = ["*"]
allow_headers     = ["*"]

[vectorDatabase]
embedding_model = "BAAI/bge-m3"
use_gpu         = "false"

[opcua]
opcua_interval = "2000"

[llm]
use_local_LLM  = "true"

llm_local_fileName  = "qwen2-1_5b-instruct-q4_k_m.gguf"
llm_local_ctxsize   = "8192"
llm_local_layers    = "40"
llm_local_batchsize = "256"

;groq config
;llm_cloud_hoster = "groq"
;llm_cloud_model  = "llama3-8b-8192"
;llm_cloud_model  = "llama3-70b-8192"
;llm_cloud_model  = "mixtral-8x7b-32768"
;llm_cloud_model  = "gemma-7b-it"
;llm_cloud_model  = "gemma2-9b-it"

;openai config
;llm_cloud_hoster = "openai"
;llm_cloud_model  = "gpt-4o"
;llm_cloud_model  = "gpt-3.5"
;llm_cloud_model  = "gpt-4"
;llm_cloud_model  = "gpt-3.5-turbo-instruct"

;cohere config
llm_cloud_hoster = "cohere"
;llm_cloud_model  = "command-r-plus"
llm_cloud_model  = "command-r"

[test_nbh630]
type = "nbh630"
ip_address = "127.0.0.1"
port = "4840"
vdb_name = "nbh630"
from_node_id = "ns=2;i=2"
to_node_id = "ns=2;i=34"
additional_prompt = ""
opcua_use_certificate = "false"
opcua_username = ""
opcua_password = ""

[test_nbh700]
type = "nbh700"
ip_address = "127.0.0.1"
port = "4841"
vdb_name = "nbh700"
from_node_id = "ns=2;i=2"
to_node_id = "ns=2;i=34"
additional_prompt = ""
opcua_use_certificate = "false"
opcua_username = ""
opcua_password = ""