from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate
from typing import Any, Optional
from langchain_community.vectorstores import FAISS
from src.Cache import Cache

# Import logging
from src.loggingConfig import logger

class RAG:
    def __init__(self, llm: Optional[object], vdb: FAISS, cache: Cache) -> None:
        """
        Initialize the RAG instance with an LLM, a VDB instance, and a cache.

        :param llm: The large language model instance.
        :param vdb: The virtual database instance for retrieving data.
        :param cache: The cache for storing and retrieving query results.
        """
        self.llm: Optional[object] = llm
        self.vdb: FAISS = vdb
        self.cache: Cache = cache
        self.loadedVDBType: Optional[str] = None
        logger.info("RAG system initialized.")

    def ensureCorrectVDB(self, machineType: str) -> None:
        """
        Ensure the correct virtual database (VDB) is loaded based on the machine type.

        :param machineType: The type of machine to ensure the VDB is loaded for.
        """
        if machineType != self.loadedVDBType:
            logger.info(f"Machine type {machineType} is different from current VDB type {self.loadedVDBType}. Loading new VDB...")
            self.vdb.loadVDB(machineType)
            self.loadedVDBType = machineType
            logger.info(f"VDB loaded for machine type {machineType}.")

    async def retrieve(
        self, machineType: str, machineName: str, errorMessage: str, additionalPrompt: str = ""
    ) -> str:
        """
        Retrieve data using the RAG system and send a response based on the machine's message and type.

        :param machineType: The type of machine sending the message.
        :param machineName: The name of the machine.
        :param errorMessage: The error message from the machine.
        :param additionalPrompt: Any additional prompt information (optional).
        :return: The response text generated by the RAG system.
        """
        logger.info(f"Received request from machine {machineName} of type {machineType}.")

        # Ensure the correct VDB is loaded
        self.ensureCorrectVDB(machineType)

        # Create retriever from the VDB
        retriever = self.vdb.vdb.as_retriever()

        # Construct the query with or without the additional prompt
        query = (
            f"Die Maschine {machineType} sendet eine Nachricht, und die Zusatzinformation {additionalPrompt}. "
            f"Die Nachricht lautet {errorMessage}. Was bedeutet diese Nachricht? antworte AUSSCHLIESSLICH auf Deutsch!"
            if additionalPrompt else
            f"Die Maschine {machineType} sendet eine Nachricht. Die Nachricht lautet {errorMessage}. "
            "Was bedeutet diese Nachricht? antworte AUSSCHLIESSLICH auf Deutsch!"
        )

        template = """
            Du bist ein Assistent fÃ¼r die Beantwortung von Fragen.
            Beantworte die Frage mit Hilfe der folgenden Kontextinformationen.
            Wenn du die Antwort nicht weisst, sag einfach, dass du sie nicht weisst.
            Frage: {question} 

            Kontext: {context} 

            Antwort:
            """
        prompt = ChatPromptTemplate.from_template(template)

        # Check the cache first
        cachedResponse = self.cache.getCachedResponse(query)
        if cachedResponse:
            logger.info(f"Cache hit for machine {machineType}. Returning cached response.")
            return cachedResponse

        # Define a function to format retrieved documents
        def formatDocs(docs: Any) -> str:
            return "\n\n".join(doc.page_content for doc in docs)

        # Create the RAG chain
        ragChain = (
            {"context": retriever | formatDocs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )

        # Invoke the RAG chain with the query and generate the response
        try:
            text = ragChain.invoke(query)
            logger.info(f"RAG response generated for machine {machineName}: {text}")
        except Exception as e:
            logger.error(f"Error generating RAG response for machine {machineName}: {e}")
            return f"Error processing the request for machine {machineName}"

        # Cache the response for future use
        self.cache.cacheResponse(query, text)
        logger.info(f"Response cached for future use: {query}")

        return text